version: '3'

services:
  # OpenWebUI service
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:3000"
    environment:
      - HOST=0.0.0.0
      - PORT=3000
      - WEBUI_AUTH=false
      - WEBUI_DB_BACKEND=sqlite
      - DEFAULT_MODEL=gpt-4o
      - OPENAI_API_KEY=sk-litellm-master-key-123456
      - OPENAI_API_BASE_URL=http://litellm:4000/v1
      - OPENAI_API_MODELS=gpt-4,gpt-4o
    depends_on:
      litellm:
        condition: service_started
    volumes:
      - openwebui_data:/app/backend/data
    restart: unless-stopped


  # LiteLLM Proxy service
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "8000:4000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PORT=4000
      - MODEL_TYPE=openai
      - LITELLM_MASTER_KEY=sk-litellm-master-key-123456
      - LITELLM_SALT_KEY=sk-litellm-salt-key-123456
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/litellm
      - STORE_MODEL_IN_DB=True
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    volumes:
      - ./config/litellm_config.yaml:/app/config.yaml
      - ./rag-pipeline:/app/rag-pipeline  # Mount custom RAG code for pre-hook injection
    command: ["--config", "/app/config.yaml", "--detailed_debug"]

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # PostgreSQL Database
  postgres:
    image: postgres:14
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=litellm
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    
  # Redis for LiteLLM caching
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    restart: unless-stopped


  # Caddy reverse proxy with Google authentication
  caddy:
    build:
      context: ./config/caddy
      dockerfile: Dockerfile
    ports:
      - "80:80"
      - "443:443"
    environment:
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - DOMAIN=${DOMAIN:-localhost}
      - ALLOWED_EMAIL_DOMAIN=${ALLOWED_EMAIL_DOMAIN:-gmail.com}
    volumes:
      - ./config/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
      - caddy_logs:/var/log/caddy
    depends_on:
      - openwebui
    restart: unless-stopped

volumes:
  openwebui_data:
  postgres_data:  # Persistent volume for PostgreSQL data
  redis_data:  # Persistent volume for Redis data
  caddy_data:  # Persistent volume for Caddy certificates
  caddy_config:  # Persistent volume for Caddy configuration
  caddy_logs:  # Persistent volume for Caddy logs
